{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "主要负责检查之前的机器学习模型是否有效：\n",
    "- 捞取的事件范围是20170801-20170820\n",
    "- 从上述的事件里面的不重复maxent_id里面获取1000个maxent_id\n",
    "- 如果上述的数据做为泛化测试集，检测出的欺诈准确率高于10%，或者至少高于5%，那么就说明模型是有效的\n",
    "- 如果低于或者等于5%，那么说明模型失效"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function,division\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from Pic.maxent_font import tick_font\n",
    "from datetime import datetime, timedelta\n",
    "from Utils.common.transfer_event_dev import transfer_event_to_device\n",
    "from sklearn.svm import SVC\n",
    "from Utils.common.MultiColumnLabelEncoder import MultiColumnLabelEncoder\n",
    "# from Algorithm.qiancheng_stack_algorithm import stack_algorithm\n",
    "from sklearn.externals import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    df = pd.read_csv(path)\n",
    "    anormaly = re.compile('.*anomaly$')\n",
    "    anormaly_match = np.vectorize(lambda x: bool(anormaly.match(x)))\n",
    "    anormaly_cols = df.columns.values[anormaly_match(df.columns.values)]\n",
    "    value = re.compile('.*value$')\n",
    "    value_match = np.vectorize(lambda x: bool(value.match(x)))\n",
    "    value_cols = df.columns.values[value_match(df.columns.values)]\n",
    "    count = re.compile('.*counts$')\n",
    "    count_match = np.vectorize(lambda x: bool(count.match(x)))\n",
    "    count_cols = df.columns.values[count_match(df.columns.values)]\n",
    "    loan = re.compile('.*loan$')\n",
    "    loan_match = np.vectorize(lambda x: bool(loan.match(x)))\n",
    "    loan_cols = df.columns.values[loan_match(df.columns.values)]\n",
    "    df[anormaly_cols] = df[anormaly_cols].fillna(1)\n",
    "    df[value_cols] = df[value_cols].fillna(1)\n",
    "    df[loan_cols] = df[loan_cols].fillna(0)\n",
    "    df[count_cols] = df[count_cols].fillna(0)\n",
    "    df['label'] = df['label'].fillna(0)\n",
    "    old_names = anormaly_cols.tolist() + value_cols.tolist()\n",
    "    new_names = map(lambda x: x.replace(\"_\", \".\"), old_names)\n",
    "    df.rename(columns=dict(zip(old_names, new_names)), inplace=True)\n",
    "    return df\n",
    "\n",
    "def df_main(df,os='ios'):\n",
    "    df = df.loc[df.os == os]\n",
    "    bool_cols = df.select_dtypes(include=[np.bool_]).columns.tolist()\n",
    "    obj_cols = df.select_dtypes(include=[np.object_]).columns.tolist()\n",
    "    encoder_cols = bool_cols + obj_cols\n",
    "    if 'maxent_id' in encoder_cols:\n",
    "        encoder_cols.remove('maxent_id')\n",
    "    df = MultiColumnLabelEncoder(columns=encoder_cols).fit_transform(df)\n",
    "    if os == 'ios':\n",
    "        col_drop = ['os', 'aid_loan', 'imei_loan', 'mac_loan', 'imei_counts', 'mac_counts', 'aid_counts']\n",
    "    else:\n",
    "        col_drop = ['os','idfa_loan', 'idfa_counts', 'idfv_counts', 'imei_loan']\n",
    "\n",
    "    df = df.drop(col_drop,axis=1)\n",
    "    return df\n",
    "\n",
    "def get_maxent_ids(df,os,path,num=None):\n",
    "    print(\"get {0} maxent_id to {1}\".format(os,path))\n",
    "    csv_file = path + \"/{0}_maxent_id.csv\".format(os)\n",
    "    label_csv_file = path + \"/{0}_label_maxent_id.csv\".format(os)\n",
    "    qiancheng_maxent_ids_file = path + \"/qiancheng_fraud_maxent_id.csv\"\n",
    "    df = df_main(df=df,os=os)\n",
    "    df = df.reset_index(drop=True)\n",
    "    maxent_id_all = df['maxent_id']\n",
    "    df = df.drop(['maxent_id'], axis=1)\n",
    "    X_test = df.ix[:, df.columns != 'label']\n",
    "    rf_model_path = '/Users/chaoxu/code/local-spark/Analysis/qiancheng/script/{0}_random_forest.pkl'\\\n",
    "        .format(os)\n",
    "    clf_rf = joblib.load(rf_model_path)\n",
    "    y_pred = clf_rf.predict(X_test)\n",
    "    maxent_id_index = np.where(y_pred == 1)\n",
    "    maxent_id = maxent_id_all.ix[maxent_id_index]\n",
    "    qiancheng_maxent_ids = pd.read_csv(qiancheng_maxent_ids_file,names=['maxent_id'])\n",
    "    if num is not None:\n",
    "        maxent_id_sample = maxent_id.sample(n=num)\n",
    "        fraud_qiancheng_index = qiancheng_maxent_ids['maxent_id'].isin(maxent_id_sample)\n",
    "        fraud_qiancheng = qiancheng_maxent_ids[fraud_qiancheng_index]\n",
    "        fraud_qiancheng.to_csv(path_or_buf=label_csv_file,index=False,header=False)\n",
    "        maxent_id_sample.to_csv(path=csv_file,index=False,header=False)\n",
    "    else:\n",
    "        fraud_qiancheng_index = qiancheng_maxent_ids['maxent_id'].isin(maxent_id)\n",
    "        fraud_qiancheng = qiancheng_maxent_ids[fraud_qiancheng_index]\n",
    "        fraud_qiancheng.to_csv(path_or_buf=label_csv_file,index=False,header=False)\n",
    "        maxent_id.to_csv(path=csv_file,index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "file = \"/Users/chaoxu/code/local-spark/Data/qiancheng_data/qiancheng_dev_merge/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = read_data(path=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.maxent_id.drop_duplicates().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android = df_main(df,os='android')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios = df_main(df,os='ios')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios.loc[df_ios.label == 1]['did.15m.anomaly'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_file = \"/Users/chaoxu/code/local-spark/Data/qiancheng_data/qiancheng_sample_new_merge_0.09/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from Utils.qiancheng.get_data import read_data as tr_read_data\n",
    "df_train = tr_read_data(train_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_os_train(df,os='ios'):\n",
    "    df = df.loc[df.os == os]\n",
    "    bool_cols = df.select_dtypes(include=[np.bool_]).columns.tolist()\n",
    "    obj_cols = df.select_dtypes(include=[np.object_]).columns.tolist()\n",
    "    encoder_cols = bool_cols + obj_cols\n",
    "    if 'maxent_id' in encoder_cols:\n",
    "        encoder_cols.remove('maxent_id')\n",
    "    df = MultiColumnLabelEncoder(columns=encoder_cols).fit_transform(df)\n",
    "    if os == 'ios':\n",
    "        col_drop = ['os','maxent_id', 'aid_loan', 'imei_loan', 'mac_loan', 'imei_counts', 'mac_counts', 'aid_counts']\n",
    "    else:\n",
    "        col_drop = ['os','maxent_id', 'idfa_loan', 'idfa_counts', 'idfv_counts', 'imei_loan']\n",
    "\n",
    "    df = df.drop(col_drop,axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_ios = get_os_train(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_ios.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_ios.loc[df_train_ios.label == 1]['did.15m.anomaly'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train_android = get_os_train(df_train,os='android')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train_android.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [u'maxentID.6h.anomaly', u'did.5m.anomaly', u'maxentID.7d.anomaly',\n",
    "       u'maxentID.5m.anomaly', u'mcid_counts', u'cracked.anomaly',\n",
    "       u'ipSeg24.15m.value', u'ipGeo.1d.anomaly', u'ipGeo.5m.anomaly',\n",
    "       u'cracked.value', u'idcIP.value', u'did.15m.anomaly',\n",
    "       u'maxentID.1h.value', u'maxentID.5m.value', u'ipSeg24.1h.anomaly',\n",
    "       u'idfv_counts', u'ipGeo.7d.anomaly', u'uaMismatch.anomaly',\n",
    "       u'ipGeo.1d.value', u'did.7d.anomaly', u'maxentID.15m.anomaly',\n",
    "       u'idfa_loan', u'ipGeo.7d.value', u'ipGeo.15m.value', u'did.5m.value',\n",
    "       u'ipSeg24.1h.value', u'maxentID.6h.value', u'ipSeg24.5m.value',\n",
    "       u'did.6h.anomaly', u'did.7d.value', u'maxentID.1d.anomaly',\n",
    "       u'ipGeo.15m.anomaly', u'ipGeo.5m.value', u'did.1h.anomaly', u'proxy_ua',\n",
    "       u'did.6h.value', u'idfa_counts', u'idcIP.anomaly', u'ipGeo.1m.anomaly',\n",
    "       u'ipGeo.1h.value', u'ipSeg24.1d.value', u'maxentID.1m.value',\n",
    "       u'proxyIP.anomaly', u'maxentID.1d.value', u'maxentID.1h.anomaly',\n",
    "       u'ipSeg24.6h.value', u'ipSeg24.1d.anomaly', u'did.1d.value',\n",
    "       u'ipSeg24.6h.anomaly', u'did.1m.value', u'ipGeo.6h.value',\n",
    "       u'did.1d.anomaly', u'ipSeg24.1m.value', u'ipSeg24.7d.anomaly',\n",
    "       u'ipGeo.1m.value', u'ipGeo.6h.anomaly', u'ipSeg24.1m.anomaly',\n",
    "       u'maxentID.15m.value', u'ipSeg24.7d.value', u'ipSeg24.5m.anomaly',\n",
    "       u'did.1m.anomaly', u'maxentID.7d.value', u'did.1h.value',\n",
    "       u'maxentID.1m.anomaly', u'did.15m.value', u'ipGeo.1h.anomaly',\n",
    "       u'ipSeg24.15m.anomaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = [u'maxentID.6h.anomaly', u'did.5m.anomaly', u'maxentID.7d.anomaly',\n",
    "       u'maxentID.5m.anomaly', u'mcid_counts', u'cracked.anomaly',\n",
    "       u'ipSeg24.15m.value', u'ipGeo.1d.anomaly', u'ipGeo.5m.anomaly',\n",
    "       u'cracked.value', u'idcIP.value', u'did.15m.anomaly',\n",
    "       u'maxentID.1h.value', u'maxentID.5m.value', u'ipSeg24.1h.anomaly',\n",
    "       u'idfv_counts', u'ipGeo.7d.anomaly', u'uaMismatch.anomaly',\n",
    "       u'ipGeo.1d.value', u'did.7d.anomaly', u'maxentID.15m.anomaly',\n",
    "       u'idfa_loan', u'ipGeo.7d.value', u'ipGeo.15m.value', u'did.5m.value',\n",
    "       u'ipSeg24.1h.value', u'maxentID.6h.value', u'ipSeg24.5m.value',\n",
    "       u'did.6h.anomaly', u'did.7d.value', u'maxentID.1d.anomaly',\n",
    "       u'ipGeo.15m.anomaly', u'ipGeo.5m.value', u'did.1h.anomaly', u'proxy_ua',\n",
    "       u'did.6h.value', u'idfa_counts', u'idcIP.anomaly', u'ipGeo.1m.anomaly',\n",
    "       u'ipGeo.1h.value', u'ipSeg24.1d.value', u'maxentID.1m.value',\n",
    "       u'proxyIP.anomaly', u'maxentID.1d.value', u'maxentID.1h.anomaly',\n",
    "       u'ipSeg24.6h.value', u'ipSeg24.1d.anomaly', u'did.1d.value',\n",
    "       u'ipSeg24.6h.anomaly', u'did.1m.value', u'ipGeo.6h.value',\n",
    "       u'did.1d.anomaly', u'ipSeg24.1m.value', u'ipSeg24.7d.anomaly',\n",
    "       u'ipGeo.1m.value', u'ipGeo.6h.anomaly', u'ipSeg24.1m.anomaly',\n",
    "       u'maxentID.15m.value', u'ipSeg24.7d.value', u'ipSeg24.5m.anomaly',\n",
    "       u'did.1m.anomaly', u'maxentID.7d.value', u'did.1h.value',\n",
    "       u'maxentID.1m.anomaly', u'did.15m.value', u'ipGeo.1h.anomaly',\n",
    "       u'ipSeg24.15m.anomaly']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "set(a) - set(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1.0,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1.0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16.0,
    "lenType": 16.0,
    "lenVar": 40.0
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
