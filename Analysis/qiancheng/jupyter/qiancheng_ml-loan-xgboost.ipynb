{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from __future__ import print_function,division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File /Users/chaoxu/code/local-spark/Data/qiancheng_sample_new.csv does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIOError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-444bea0d4c40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Users/chaoxu/code/local-spark/Data/qiancheng_sample_new.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/chaoxu/.pyenv/versions/anaconda2-4.3.1/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skipfooter, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    644\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 646\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    648\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chaoxu/.pyenv/versions/anaconda2-4.3.1/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chaoxu/.pyenv/versions/anaconda2-4.3.1/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 730\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chaoxu/.pyenv/versions/anaconda2-4.3.1/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    921\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/chaoxu/.pyenv/versions/anaconda2-4.3.1/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1388\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1390\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1392\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:4184)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:8449)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File /Users/chaoxu/code/local-spark/Data/qiancheng_sample_new.csv does not exist"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/chaoxu/code/local-spark/Data/qiancheng_sample_new.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios_test = pd.read_csv(\"/Users/chaoxu/code/local-spark/Data/qiancheng_ios_vld.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_ios_test.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android_test = pd.read_csv(\"/Users/chaoxu/code/local-spark/Data/qiancheng_android_vld.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_android_test.timestamp.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.os.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def resample(data, positiveRatio=0.04):\n",
    "    positive = data[data[\"label\"] == 1]\n",
    "    negative = data[data[\"label\"] == 0]\n",
    "    n = int((1 - positiveRatio) / positiveRatio) * positive.shape[0]\n",
    "    print(n)\n",
    "    _negative = negative.sample(n=n)\n",
    "    df = pd.concat([positive, _negative])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['label']]=df[['label']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android_test[['label']]=df_android_test[['label']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios_test[['label']]=df_ios_test[['label']].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "df[\"timestamp\"] = pd.to_datetime(df['timestamp'], unit='ms', utc=True)\n",
    "df[\"timestamp\"] = pd.DatetimeIndex(df[\"timestamp\"]) + timedelta(hours=8)\n",
    "df = df.sort_values(by=\"timestamp\")\n",
    "df = df.drop(['idcIP.anomaly', 'cracked.anomaly', 'uaMismatch.anomaly',\"timestamp\",\"maxent_id\",\"timestamp\",'ipSeg24','ipGeo','event_id','scenario'],axis=1)\n",
    "df[['label']]=df[['label']].fillna(0)\n",
    "df[['label']] = df[['label']].astype(int)\n",
    "df = df.loc[df['event_type'] =='ACT']\n",
    "df = df.drop(['event_type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android_test[\"timestamp\"] = pd.to_datetime(df_android_test['timestamp'], unit='ms', utc=True)\n",
    "df_android_test[\"timestamp\"] = pd.DatetimeIndex(df_android_test[\"timestamp\"]) + timedelta(hours=8)\n",
    "df_android_test = df_android_test.sort_values(by=\"timestamp\")\n",
    "df_android_test = df_android_test.drop(['idcIP.anomaly', 'cracked.anomaly', 'uaMismatch.anomaly',\"timestamp\",\"maxent_id\",\"timestamp\",'ipSeg24','ipGeo','event_id','scenario'],axis=1)\n",
    "df_android_test[['label']]=df_android_test[['label']].fillna(0)\n",
    "df_android_test[['label']] = df_android_test[['label']].astype(int)\n",
    "df_android_test = df_android_test.loc[df_android_test['event_type'] =='ACT']\n",
    "df_android_test = df_android_test.drop(['event_type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios_test[\"timestamp\"] = pd.to_datetime(df_ios_test['timestamp'], unit='ms', utc=True)\n",
    "df_ios_test[\"timestamp\"] = pd.DatetimeIndex(df_ios_test[\"timestamp\"]) + timedelta(hours=8)\n",
    "df_ios_test = df_ios_test.sort_values(by=\"timestamp\")\n",
    "df_ios_test = df_ios_test.drop(['idcIP.anomaly', 'cracked.anomaly', 'uaMismatch.anomaly',\"timestamp\",\"maxent_id\",\"timestamp\",'ipSeg24','ipGeo','event_id','scenario'],axis=1)\n",
    "df_ios_test[['label']]=df_ios_test[['label']].fillna(0)\n",
    "df_ios_test[['label']] = df_ios_test[['label']].astype(int)\n",
    "df_ios_test = df_ios_test.loc[df_ios_test['event_type'] =='ACT']\n",
    "df_ios_test = df_ios_test.drop(['event_type'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "anormaly = re.compile('.*anomaly$')\n",
    "anormaly_match = np.vectorize(lambda x:bool(anormaly.match(x)))\n",
    "anormaly_cols = df.columns.values[anormaly_match(df.columns.values)]\n",
    "\n",
    "value = re.compile('.*value$')\n",
    "value_match = np.vectorize(lambda x:bool(value.match(x)))\n",
    "value_cols = df.columns.values[value_match(df.columns.values)]\n",
    "\n",
    "count = re.compile('.*counts$')\n",
    "count_match = np.vectorize(lambda x:bool(count.match(x)))\n",
    "count_cols = df.columns.values[count_match(df.columns.values)]\n",
    "\n",
    "loan = re.compile('.*loan$')\n",
    "loan_match = np.vectorize(lambda x:bool(loan.match(x)))\n",
    "loan_cols = df.columns.values[loan_match(df.columns.values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cols = df.columns\n",
    "fig, ax = plt.subplots(figsize=(16,9))\n",
    "ax.barh(range(len(cols)),df[cols].isnull().sum()/df.shape[0])\n",
    "ax.set_yticks(range(len(cols)))\n",
    "ax.set_yticklabels(cols, size=14)\n",
    "ax.set_title('features nan percentage',size= 18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[loan_cols]=df[loan_cols].fillna(0)\n",
    "df_android_test[loan_cols]=df_android_test[loan_cols].fillna(0)\n",
    "df_ios_test[loan_cols]=df_ios_test[loan_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[anormaly_cols] = df[anormaly_cols].fillna(1)\n",
    "df[value_cols] = df[value_cols].fillna(1)\n",
    "df_android_test[anormaly_cols] = df_android_test[anormaly_cols].fillna(1)\n",
    "df_android_test[value_cols] = df_android_test[value_cols].fillna(1)\n",
    "df_ios_test[anormaly_cols] = df_ios_test[anormaly_cols].fillna(1)\n",
    "df_ios_test[value_cols] = df_ios_test[value_cols].fillna(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj_df = df.select_dtypes(include=['object'])\n",
    "obj_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bool_df = df.select_dtypes(include=['bool'])\n",
    "bool_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[count_cols]=df[count_cols].fillna(0)\n",
    "df_android_test[count_cols]=df_android_test[count_cols].fillna(0)\n",
    "df_ios_test[count_cols]=df_ios_test[count_cols].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_missing():\n",
    "    missing = df.columns[df.isnull().any()].tolist()\n",
    "    return missing\n",
    "df[show_missing()].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "整体的label平衡性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.label.value_counts(normalize=True).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios = df.loc[df.os == 'ios']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_ios = resample(df_ios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obj_cols = obj_df.columns.values.tolist()\n",
    "print(obj_cols)\n",
    "bool_cols = bool_df.columns.values.tolist()\n",
    "print(bool_cols)\n",
    "encoder_cols = obj_cols + bool_cols\n",
    "print(encoder_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "class MultiColumnLabelEncoder:\n",
    "    def __init__(self,columns = None):\n",
    "        self.columns = columns # array of column names to encode\n",
    "\n",
    "    def fit(self,X,y=None):\n",
    "        return self # not relevant here\n",
    "\n",
    "    def transform(self,X):\n",
    "        '''\n",
    "        Transforms columns of X specified in self.columns using\n",
    "        LabelEncoder(). If no columns specified, transforms all\n",
    "        columns in X.\n",
    "        '''\n",
    "        output = X.copy()\n",
    "        if self.columns is not None:\n",
    "            for col in self.columns:\n",
    "                output[col] = LabelEncoder().fit_transform(output[col])\n",
    "        else:\n",
    "            for colname,col in output.iteritems():\n",
    "                output[colname] = LabelEncoder().fit_transform(col)\n",
    "        return output\n",
    "\n",
    "    def fit_transform(self,X,y=None):\n",
    "        return self.fit(X,y).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios = MultiColumnLabelEncoder(columns = encoder_cols).fit_transform(df_ios)\n",
    "df_ios_test = MultiColumnLabelEncoder(columns = encoder_cols).fit_transform(df_ios_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios.label.value_counts(normalize=True).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def show_missing():\n",
    "    missing = df.columns[df.isnull().any()].tolist()\n",
    "    return missing\n",
    "df_ios[show_missing()].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cols = df_ios.columns\n",
    "# fig, ax = plt.subplots(figsize=(16,9))\n",
    "# ax.barh(range(len(cols)),df_ios[cols].isnull().sum()/df_ios.shape[0])\n",
    "# ax.set_yticks(range(len(cols)))\n",
    "# ax.set_yticklabels(cols, size=14)\n",
    "# ax.set_title('features nan percentage',size= 18)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ios_drop = ['os','aid_loan','imei_loan','mac_loan','imei_counts','mac_counts','aid_counts']\n",
    "df_ios.drop(ios_drop,axis=1)\n",
    "df_ios_test.drop(ios_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_ios.label.value_counts(normalize=True).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X_ios = df_ios.ix[:, df_ios.columns != 'label']\n",
    "# y_ios = df_ios.ix[:, df_ios.columns == 'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from sklearn.cross_validation import train_test_split\n",
    "# def splitData(df, ratio):\n",
    "#     \"\"\"\n",
    "#     \"\"\"\n",
    "#     positiveData = df[df[\"label\"] == 1].copy(deep=True)\n",
    "#     _positiveTrain, _positiveTest = train_test_split(positiveData, train_size=ratio)\n",
    "#     negativeData = df[df[\"label\"] == 0].copy(deep=True)\n",
    "#     _negativeTrain, _negativeTest = train_test_split(negativeData, train_size=ratio)\n",
    "#     train_set = pd.concat([_positiveTrain, _negativeTrain])\n",
    "#     test_set = pd.concat([_positiveTest, _negativeTest])\n",
    "#     return train_set, test_set\n",
    "\n",
    "df_ios_train = df_ios\n",
    "X_ios_train = df_ios_train.ix[:, df_ios_train.columns != 'label']\n",
    "X_ios_test  = df_ios_test.ix[:, df_ios_test.columns != 'label']\n",
    "y_ios_train = df_ios_train.ix[:, df_ios_train.columns == 'label']\n",
    "y_ios_test  = df_ios_test.ix[:, df_ios_test.columns == 'label']\n",
    "print(\"Number transactions ios train dataset: \", X_ios_train.shape[0])\n",
    "print(\"Number transactions ios train dataset: \", y_ios_train.shape[0])\n",
    "print(\"Number transactions ios test dataset: \", X_ios_test.shape[0])\n",
    "print(\"Total number of ios transactions: \", X_ios_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ios_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function,division\n",
    "import itertools\n",
    "import matplotlib.pylab as plt\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=0)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        #print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        1#print('Confusion matrix, without normalization')\n",
    "\n",
    "    #print(cm)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('label 1')\n",
    "    plt.xlabel('label 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,precision_score,classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "params = {'max_features':'auto', 'max_depth': 3, 'min_samples_split': 5, \\\n",
    "            'class_weight':'balanced','oob_score':True}\n",
    "params['n_estimators'] = 2\n",
    "params['n_jobs'] = 50\n",
    "forest = RandomForestClassifier(**params)\n",
    "clf_a = forest.fit(X_ios_train,y_ios_train.values.ravel())\n",
    "y_ios_pred = clf_a.predict(X_ios_test)\n",
    "\n",
    "print(X_ios_test.size)\n",
    "print(y_ios_test.size)\n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_ios_test,y_ios_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(precision=2)\n",
    "recall = cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1])\n",
    "precision = cnf_matrix[1,1]/(cnf_matrix[0,1]+cnf_matrix[1,1])\n",
    "f2 = 0.2*(4/recall + 1/precision)\n",
    "print(\"Recall metric in the testing dataset: \", recall)\n",
    "print(\"Precision metric in the testting dataset:\", precision)\n",
    "print(\"f2 metric in the testting dataset:\", f2)\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_ios_test, y_ios_pred, target_names=['0','1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_ios_neg = y_ios_train.loc[y_ios_train.label == 1].shape[0]\n",
    "sum_ios_pos = y_ios_train.loc[y_ios_train.label == 0].shape[0]\n",
    "scale_ios_ratio = sum_ios_neg / sum_ios_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_ios_params1 = {\n",
    "    'objective' : 'binary:logistic',\n",
    "#     'objective' : 'binary:logitraw',\n",
    "    'nthread':4,\n",
    "#     'num_class': 2,\n",
    "    'scale_pos_weight':scale_ios_ratio,\n",
    "#     'missing':-6.666,\n",
    "    'seed':27 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cv_params = {\n",
    "    'pre_dispatch': '2*n_jobs', \n",
    "    'refit':True,\n",
    "    'scoring':'roc_auc',\n",
    "#     'scoring':'f1_macro',\n",
    "#     'scoring':'average_precision',\n",
    "#     'scoring':'accuracy',\n",
    "#     'scoring':'recall',\n",
    "    'cv':5,\n",
    "    'verbose':0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_ios_test2 = {\n",
    "    'n_estimators':range(10,200,10)\n",
    "}\n",
    "params_ios = {}\n",
    "params_ios.update(xgb_ios_params1)\n",
    "xgb_params2 = params_ios\n",
    "xgb_params2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch1_ios = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_params2),\n",
    "                        param_grid=param_ios_test2,**cv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_ios_cols = X_ios_train.columns\n",
    "gsearch1_ios.fit(X_ios_train[X_ios_cols],y_ios_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch1_ios.grid_scores_, gsearch1_ios.best_params_, gsearch1_ios.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_ios.update(gsearch1_ios.best_params_)\n",
    "params_ios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_ios_params3 = params_ios\n",
    "param_ios_test3 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch3_ios = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_ios_params3),\n",
    "                        param_grid=param_ios_test3,**cv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch3_ios.fit(X_ios_train[X_ios_cols],y_ios_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch3_ios.grid_scores_, gsearch3_ios.best_params_, gsearch3_ios.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_ios.update(gsearch3_ios.best_params_)\n",
    "params_ios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_ios_params4 = params_ios\n",
    "param_ios_test4 = {\n",
    "    'gamma':[i/10.0 for i in range(0,5)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch4_ios = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_ios_params4),\n",
    "                        param_grid=param_ios_test4,**cv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch4_ios.fit(X_ios_train[X_ios_cols],y_ios_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch4_ios.grid_scores_, gsearch4_ios.best_params_, gsearch4_ios.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_ios.update(gsearch4_ios.best_params_)\n",
    "params_ios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_ios_params5 = params_ios\n",
    "param_ios_test5 = {\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch5_ios = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_ios_params5),\n",
    "                        param_grid=param_ios_test5,**cv_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch5_ios.fit(X_ios_train[X_ios_cols],y_ios_train['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch5_ios.grid_scores_, gsearch5_ios.best_params_, gsearch5_ios.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_ios.update(gsearch5_ios.best_params_)\n",
    "params_ios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_ios_params6 = params_ios\n",
    "param_ios_test6 = {\n",
    "    'reg_lambda':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "}\n",
    "gsearch6_ios = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_ios_params6),\n",
    "                        param_grid=param_ios_test6,**cv_params)\n",
    "gsearch6_ios.fit(X_ios_train[X_ios_cols],y_ios_train['label'])\n",
    "gsearch6_ios.grid_scores_, gsearch6_ios.best_params_, gsearch6_ios.best_score_\n",
    "params_ios.update(gsearch6_ios.best_params_)\n",
    "params_ios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_np = np.arange(0.1,0.2,0.02).tolist()\n",
    "xgb_ios_params7 = params_ios\n",
    "param_ios_test7 = {\n",
    "    'learning_rate':l_np\n",
    "}\n",
    "gsearch7_ios = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_ios_params7),\n",
    "                        param_grid=param_ios_test7,**cv_params)\n",
    "gsearch7_ios.fit(X_ios_train[X_ios_cols],y_ios_train['label'])\n",
    "gsearch7_ios.grid_scores_, gsearch7_ios.best_params_, gsearch7_ios.best_score_\n",
    "params_ios.update(gsearch7_ios.best_params_)\n",
    "params_ios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = np.arange(0.1,1.0,0.1).tolist()\n",
    "xgb_ios_params8 = params_ios\n",
    "param_ios_test8 = {\n",
    "    'base_score':scores\n",
    "}\n",
    "gsearch8_ios = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_ios_params8),\n",
    "                        param_grid=param_ios_test8,**cv_params)\n",
    "gsearch8_ios.fit(X_ios_train[X_ios_cols],y_ios_train['label'])\n",
    "gsearch8_ios.grid_scores_, gsearch8_ios.best_params_, gsearch8_ios.best_score_\n",
    "params_ios.update(gsearch8_ios.best_params_)\n",
    "params_ios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_learning_curves\n",
    "xgb_ios_final = xgb.XGBClassifier(**params_ios)\n",
    "y_ios_train_f = y_ios_train.label.astype(float)\n",
    "y_ios_test_f = y_ios_test.label.astype(float)\n",
    "plot_learning_curves(X_ios_train, y_ios_train_f, X_ios_test, y_ios_test_f, xgb_ios_final, print_model=False, style='ggplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(figsize=(10,10))\n",
    "xgb.plot_importance(xgb_ios_final,ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(figsize=(10,10))\n",
    "# xgb.plot_tree(xgb_ios_final,num_trees=59,ax=ax)\n",
    "xgb.plot_tree(xgb_ios_final,ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "xgb_ios_final.fit(X_ios_train, y_ios_train)\n",
    "y_ios_pred = xgb_ios_final.predict(X_ios_test)\n",
    "cnf_matrix = confusion_matrix(y_ios_test,y_ios_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(precision=2)\n",
    "recall = cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1])\n",
    "precision = cnf_matrix[1,1]/(cnf_matrix[0,1]+cnf_matrix[1,1])\n",
    "f2 = 0.2*(4/recall + 1/precision)\n",
    "print(\"Recall metric in the testing dataset: \", recall)\n",
    "print(\"Precision metric in the testting dataset:\", precision)\n",
    "print(\"f2 metric in the testting dataset:\", f2)\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_ios_test, y_ios_pred, target_names=['0','1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android = df.loc[df.os == 'android']\n",
    "df_android = MultiColumnLabelEncoder(columns = encoder_cols).fit_transform(df_android)\n",
    "df_android_test = MultiColumnLabelEncoder(columns = encoder_cols).fit_transform(df_android_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android.label.value_counts(normalize=True).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android[show_missing()].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android['proxyIP.value'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "android_drop = ['os','idfa_loan','idfa_counts', u'idfv_counts','imei_loan']\n",
    "df_android =df_android.drop(android_drop,axis=1)\n",
    "df_android_test =df_android_test.drop(android_drop,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_android_train = df_android\n",
    "X_android_train = df_android_train.ix[:, df_android_train.columns != 'label']\n",
    "X_android_test  = df_android_test.ix[:,  df_android_test.columns != 'label']\n",
    "y_android_train = df_android_train.ix[:, df_android_train.columns == 'label']\n",
    "y_android_test  = df_android_test.ix[:,  df_android_test.columns == 'label']\n",
    "print(\"Number transactions android train dataset: \", X_android_train.shape[0])\n",
    "print(\"Number transactions android train dataset: \", y_android_train.shape[0])\n",
    "print(\"Number transactions android test dataset: \", X_android_test.shape[0])\n",
    "print(\"Total number of android transactions: \", X_android_train.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_android_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sum_android_neg = y_android_train.loc[y_android_train.label == 1].shape[0]\n",
    "sum_android_pos = y_android_train.loc[y_android_train.label == 0].shape[0]\n",
    "scale_android_ratio = sum_android_neg / sum_android_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_android_params = {\n",
    "    'objective' : 'binary:logistic',\n",
    "#     'objective' : 'binary:logitraw',\n",
    "    'nthread':4,\n",
    "#     'num_class': 2,\n",
    "#     'scale_pos_weight':scale_android_ratio,\n",
    "#     'missing':-6.666,\n",
    "    'seed':27 \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_android_test1 = {\n",
    "    'n_estimators':range(10,200,10)\n",
    "}\n",
    "params_android = {}\n",
    "params_android.update(xgb_android_params)\n",
    "xgb_android_params1 = params_android\n",
    "xgb_android_params1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gsearch1_android = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_android_params1),\n",
    "                        param_grid=param_android_test1,**cv_params)\n",
    "X_android_cols = X_android_train.columns\n",
    "gsearch1_android.fit(X_android_train[X_android_cols],y_android_train['label'])\n",
    "gsearch1_android.grid_scores_, gsearch1_android.best_params_, gsearch1_android.best_score_\n",
    "params_android.update(gsearch1_android.best_params_)\n",
    "params_android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_android_params2 = params_android\n",
    "param_android_test2 = {\n",
    "    'max_depth':range(3,10,2),\n",
    "    'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch2_android = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_android_params2),\n",
    "                        param_grid=param_android_test2,**cv_params)\n",
    "gsearch2_android.fit(X_android_train[X_android_cols],y_android_train['label'])\n",
    "gsearch2_android.grid_scores_, gsearch2_android.best_params_, gsearch2_android.best_score_\n",
    "params_android.update(gsearch2_android.best_params_)\n",
    "params_android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_android_params3 = params_android\n",
    "param_android_test3 = {\n",
    "    'gamma':[i/10.0 for i in range(0,5)]\n",
    "}\n",
    "gsearch3_android = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_android_params3),\n",
    "                        param_grid=param_android_test3,**cv_params)\n",
    "gsearch3_android.fit(X_android_train[X_android_cols],y_android_train['label'])\n",
    "gsearch3_android.grid_scores_, gsearch3_android.best_params_, gsearch3_android.best_score_\n",
    "params_android.update(gsearch3_android.best_params_)\n",
    "params_android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_android_params4 = params_android\n",
    "param_android_test4 = {\n",
    "    'subsample':[i/10.0 for i in range(6,10)],\n",
    "    'colsample_bytree':[i/10.0 for i in range(6,10)],\n",
    "}\n",
    "gsearch4_android = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_android_params4),\n",
    "                        param_grid=param_android_test4,**cv_params)\n",
    "gsearch4_android.fit(X_android_train[X_android_cols],y_android_train['label'])\n",
    "gsearch4_android.grid_scores_, gsearch4_android.best_params_, gsearch4_android.best_score_\n",
    "params_android.update(gsearch4_android.best_params_)\n",
    "params_android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_android_params5 = params_android\n",
    "param_android_test5 = {\n",
    "    'reg_lambda':[0, 0.001, 0.005, 0.01, 0.05],\n",
    "}\n",
    "gsearch5_android = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_android_params5),\n",
    "                        param_grid=param_android_test5,**cv_params)\n",
    "gsearch5_android.fit(X_android_train[X_android_cols],y_android_train['label'])\n",
    "gsearch5_android.grid_scores_, gsearch5_android.best_params_, gsearch5_android.best_score_\n",
    "params_android.update(gsearch5_android.best_params_)\n",
    "params_android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "l_np = np.arange(0.1,0.2,0.02).tolist()\n",
    "xgb_android_params6 = params_android\n",
    "param_android_test6 = {\n",
    "    'reg_lambda':l_np\n",
    "}\n",
    "gsearch6_android = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_android_params6),\n",
    "                        param_grid=param_android_test6,**cv_params)\n",
    "gsearch6_android.fit(X_android_train[X_android_cols],y_android_train['label'])\n",
    "gsearch6_android.grid_scores_, gsearch6_android.best_params_, gsearch6_android.best_score_\n",
    "params_android.update(gsearch6_android.best_params_)\n",
    "params_android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scores = np.arange(0.1,1.0,0.1).tolist()\n",
    "xgb_android_params7 = params_android\n",
    "param_android_test7 = {\n",
    "    'base_score':scores\n",
    "}\n",
    "gsearch7_android = GridSearchCV(estimator = xgb.XGBClassifier(**xgb_android_params7),\n",
    "                        param_grid=param_android_test7,**cv_params)\n",
    "gsearch7_android.fit(X_android_train[X_android_cols],y_android_train['label'])\n",
    "gsearch7_android.grid_scores_, gsearch7_android.best_params_, gsearch7_android.best_score_\n",
    "params_android.update(gsearch7_android.best_params_)\n",
    "params_android"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_android_final = xgb.XGBClassifier(**params_android)\n",
    "y_android_train_f = y_android_train.label.astype(float)\n",
    "y_android_test_f = y_android_test.label.astype(float)\n",
    "plot_learning_curves(X_android_train, y_android_train_f, X_android_test, y_android_test_f, xgb_android_final, print_model=False, style='ggplot')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(figsize=(10,10))\n",
    "xgb.plot_importance(xgb_android_final,ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig,ax= plt.subplots(figsize=(10,10))\n",
    "# xgb.plot_tree(xgb_ios_final,num_trees=59,ax=ax)\n",
    "xgb.plot_tree(xgb_android_final,ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xgb_android_final.fit(X_android_train, y_android_train)\n",
    "y_android_pred = xgb_android_final.predict(X_android_test)\n",
    "cnf_matrix = confusion_matrix(y_android_test,y_android_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "np.set_printoptions(precision=2)\n",
    "recall = cnf_matrix[1,1]/(cnf_matrix[1,0]+cnf_matrix[1,1])\n",
    "precision = cnf_matrix[1,1]/(cnf_matrix[0,1]+cnf_matrix[1,1])\n",
    "f2 = 0.2*(4/recall + 1/precision)\n",
    "print(\"Recall metric in the testing dataset: \", recall)\n",
    "print(\"Precision metric in the testting dataset:\", precision)\n",
    "print(\"f2 metric in the testting dataset:\", f2)\n",
    "# Plot non-normalized confusion matrix\n",
    "class_names = [0,1]\n",
    "plt.figure()\n",
    "plot_confusion_matrix(cnf_matrix\n",
    "                      , classes=class_names\n",
    "                      , title='Confusion matrix')\n",
    "plt.show()\n",
    "\n",
    "print(classification_report(y_android_test, y_android_pred, target_names=['0','1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
