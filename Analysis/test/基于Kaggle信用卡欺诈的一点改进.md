## 基于Kaggle信用卡欺诈的一点改进

## 学习器性能评价

### 基本出发点

因为是欺诈检测，所以更加看重查全率，也叫召回率（Recall）

#### 查准率，查全率

- 查准率（也叫准确率）： 关心的是查出了异常占整体样本的比例。
- 查全率（也叫召回率）： 关心的是查出的异常占所有异常的比率。

通常使用的是查准率来衡量模型的好坏， 但是异常检测的时候，使用查准率实际没有太大的意义。 假设9999个normal样本，10个unnormal样本，模型如果检测出了着9999个为正常常，但是10个异常没有检测出，根据准确率公式：
$$
P = \frac{TP}{TP+FP}
$$
查准率为1， 看似性能很高，实际明显不合理，所以在实际考虑泛化能力的时候，查全率更加重要。
$$
R = \frac{TP}{TP+FN}
$$
其中TP,FP,FN,TN定义如下：

- TP : TRUE positive
- FP： FALSE positive
- FN：FALSE negative
- TN： TRUE positive

| 真实情况 | 预测结果 | 预测结果 |
| ---- | ---- | ---- |
|      | 正例   | 反例   |
| 正例   | TP   | FN   |
| 反例   | FP   | TN   |

> 查准率与查全率是一对矛盾的度量，通常来说，查准率越高，查全率越低；而查全率高的时候，查准率低。只有在一些简单的任务中，才会出现查准率与查全率同时高的情况。

实际模型性能衡量的时候，既要考虑欺诈的查全，也要尽量避免误杀，这就要求查准率也要衡量。考虑到查全率在异常检测中更加重要的特点，结合$F_β$系数：
$$
F_β = \frac{(1+β^2) * P*R}{(β^2 * P) +R}
$$
当β大于1的时候，查全率更加重要，取β=2有：
$$
F_β = \frac{1}{(1+β^2) }(\frac{1}{P} + \frac{β^2}{R})=\frac{1}{5}(\frac{1}{P} + \frac{4}{R})
$$

### 统计假设检验

> 统计假设检验为我们进行学习器性能比较提供了重要依据。基于假设检验的结果，我们可以推断出，若在测试集上面观察到学习器A比B好，则A的泛化性能在多大统计把握度下面优于B。

机器学习性能比较要考虑的更加全面，而不是简单的比较$F_β$系数大小。主要涉及以下几个因素：

1. 需要比较的是泛化能力，然而泛化能力是通过测试集上的性能去近似，两者结果不一定相同
2. 测试集的性能与测试集选择有很大的关系
3. 很多机器学习算法本身有一定的随机性，即使使用相同的参数，相同的数据集，运行多次得到的结果也可能会不同。

所以需要使用统计假设的检验方法来对我们的模型好坏做出统计学上的评估。 本文以错误率$ε$为性能度量，使用$χ^2$检测作为学习器性能检验方法。

#### 卡方检测

对于二分类问题，通过列联表的方法，如下表所示：

|      | 算法A      | 算法A      |
| ---- | -------- | -------- |
| 算法B  | 正确       | 错误       |
| 正确   | $e_{00}$ | $e_{01}$ |
| 错误   | $e_{10}$ | $e_{11}$ |

如果我们假设两个学习器的性能相同，那么有$e_{01} == e_{10}$, 而且变量$|e_{01} - e_{10}|$应当符合正太分布，而且均值为1，方差为$|e_{01} + e_{10}|$。 所以变量:
$$
τ_{χ^2} = \frac{(|e_{01} - e_{10}|-1)^2}{|e_{01} + e_{10}|}
$$
服从自由度为1的$χ^2$分布。 给定显著度α，当以上变量小于$χ^2_α$的时候，不能拒绝假设两个学习器性能相等的假设；反之则认为==两个学习器的性能不相等，而且平均错误率更小的那个学习器性能更强==。自由度为1的$χ^2$分布，当α=0.05的时候为3.8415.

## 数据倾斜

- 原先的解决方案里面采用的是下采样，衡量标准是recall大小，本文尝试使用SMOTE算法对数据偏斜进行处理，同时使用$F_2$作为交叉验证的衡量标准。

- 使用SMOTE算法， 对切斜数据进行过采样，在新产生的数据集上得到的$F_β$结果是，1.0100060578，混淆矩阵如下图所示：

  ![cofusion](../Image/cofusion.png)

## SMOTE算法简介

> 样本不平衡，严重影响模型的准确性，会导致模型在正例上过拟合，在反例上欠拟合。

通常解决办法分为以下几种（异常检测一般都是正例远超过反例的数量，可以通过柱状图显示）：

1. 对正例下采样，也就是通过对正例进行采样，获取与反例几乎相同数量的样本。
2. 对反例进行过采样，产生于正例几乎相同的样本数量。
3. 使用SMOTE方法，产生大量的反例样本。

此处模型使用的是SMOTE方法，产生样本平衡的样本数据，然后在使用对应的机器学习模型。

### SMOTE简介

 SMOTE算法实际很简单，首先随机选取n个少类的样本：

![选取第一个少类样本](http://upload-images.jianshu.io/upload_images/1129359-5782835263511a07.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

然后在找出最靠近它的m个少类样本，如下图：

![](http://upload-images.jianshu.io/upload_images/1129359-9fa8ec63346c4684.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

最后选最临近的m个少类样本中的任意一点，如图：

![](http://upload-images.jianshu.io/upload_images/1129359-dad1a4b19048d4ac.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)

实际使用的时候，SMOTE可以分为普通SMOTE（也就是上面的线性插值）、borderline(type1, type2)、SVM等。详情以及参考文献可以参照[**imbalanced-learn**](https://github.com/scikit-learn-contrib/imbalanced-learn#id27)

使用Kaggle信用卡反欺诈数据， 采用不同的SMOTE模型过采样数据，得到以下图形:

![smoteCompare](../Image/smoteCompare.png)

可以看出SMOTE在regular下恢复的数据最多，但是很多数据与原来的分布点不大一样，SVM的话则基本与之前欺诈数据分布散状类似，故而采用SVM模式，以及birderline1模式分别尝试。

### SMOTE SVM数据倾斜

在SMOTE SVM算法，过采样产生的数据集上，获得了0.985752250723的召回率,$F_2$为1.0100060578。在原始数据上却只获得0.863945578231的召回率，$F_2$为，混淆矩阵如下图所示：

![originalSmoteConfusion](../Image/originalSmoteConfusion.png)

如下表所示。

|           | SMOTE          | Original       |
| --------- | -------------- | -------------- |
| recall    | 0.984897619912 | 0.863945578231 |
| precision | 0.990102156106 | 0.133263378804 |
| $F_2$     | 1.01429556369  | 2.4125984252   |

recall与precision均出现了下降，尤其是precision下降的比较厉害，但是$F_2$有大幅提高，跟预期不一致，怀疑是(欺诈数据)过采样造成的。这里我们在考虑一下下采样以及borderline SMOTE的方式来看看上述三个指标，并使用McNeamar检验，看看哪一个的性能才是高的。

### SMOTE Borderline数据倾斜

既然怀疑是过拟合，那么还是使用过采样产生的欺诈数据较少的border line1产生的数据集来进行训练， 看看上述三个指标的变化情况。如下图所示，其中precision：0.98754465125 ， recall：0.983925916387，$F_2$为：1.01559183285。

![borderConfusion](../Image/borderConfusion.png)

在原始数据集上的结果如下图所示， 其中precision：0.114564831261 ， recall：0.877551020408，$F_2$为：2.65736434109。

![originalSmoteBorderConfusion](../Image/originalSmoteBorderConfusion.png)

|           | SMOTE SVM      | Original-SVM   | SMOTE Border Line1 | Original-Border Line1 |
| --------- | -------------- | -------------- | ------------------ | --------------------- |
| recall    | 0.984897619912 | 0.863945578231 | 0.983925916387     | 0.877551020408        |
| precision | 0.990102156106 | 0.133263378804 | 0.98754465125      | 0.114564831261        |
| $F_2$     | 1.01429556369  | 2.4125984252   | 1.01559183285      | 2.65736434109         |

跟之前的相比， 查准率以及产权率进一步下降，但是$F_2$系数有所上升，说明两个模型很难从单一的指标上说明哪一个性能更好，故而采用McNeamar检验，看看哪一个的性能才是高的。

|      | 算法A               | 算法A              |
| ---- | ----------------- | ---------------- |
| 算法B  | 正确                | 错误               |
| 正确   | 0.988073920625    | 0.00202474164063 |
| 错误   | 3.51111267161e-05 | 0.00986622660721 |

$τ_{χ^2}$ = 1.00801092349，小于置信区间为0.95的临界值3.8415. 所以==性能一致==。也就是说在过采样的数据集下，两个学习器的性能一样。我们在来对比一下原文档的下采样的方法，进一步减少训练的样本数量，避免过拟合。

### 下采样数据倾斜

使用下采样数据训练, precision：0.901315789474 ， recall：0.931972789116，$F_2$为：1.0802919708。混淆矩阵如下图所示：

![underSampleConfuse](../Image/underSampleConfuse.png)

将该模型应用到原始数据集，获得precision：0.0156107566089，recall：0.931972789116以及$F_2$分别是13.6700729927，混淆矩阵如下图所示：

![originalUnderSampleConfuse](../Image/originalUnderSampleConfuse.png)

precision，recall进一步下降，但是$F_2$上升的非常明显。

|           | SMOTE SVM      | Original-SVM   | SMOTE Border Line1 | Original-Border Line1 | Under Sample   | Original Under Smaple |
| --------- | -------------- | -------------- | ------------------ | --------------------- | -------------- | --------------------- |
| recall    | 0.984897619912 | 0.863945578231 | 0.983925916387     | 0.877551020408        | 0.931972789116 | 0.931972789116        |
| precision | 0.990102156106 | 0.133263378804 | 0.98754465125      | 0.114564831261        | 0.901315789474 | 0.0156107566089       |
| $F_2$     | 1.01429556369  | 2.4125984252   | 1.01559183285      | 2.65736434109         | 1.0802919708   | 13.6700729927         |

还是需要从统计学的角度去衡量这个学习器的性能与前面的谁更好。 因为前面两个学习器等价，这里使用border line产生的学习器来进行比较。

|              | border line    | border line       |
| ------------ | -------------- | ----------------- |
| under sample | 正确             | 错误                |
| 正确           | 0.898329880739 | 0.000444740938403 |
| 错误           | 0.089779151013 | 0.0114462273094   |

$τ_{χ^2}$ =0.839291808925, 小于置信区间为0.95的临界值3.8415. 所以==性能一致==。 也就是说这里使用过采样或者下采样产生的学习器， 性能在95%的置信区间内是一致的。

考虑到我们更加关注查全一些，因此使用下采样产生的学习器效果更好一些。

## 使用RF

更多的异常样本反而导致了学习器性能下降，肯定存在过拟合的问题，虽然这个过拟合问题在统计角度上是可以接受的。那么我们考虑是否可以通过引入特征随机筛选的功能。RF是以决策树为基学习器构建bagging基础上，在决策树的训练过程中引入属性的随机选择。一般属性的数量选为$k=log_{2}d$。随机森林简单，容易实现，加入了随机属性的扰动，使得最终的继承泛化性能可通过个体学习器之间的差异度的增加而加强。

首先我们需要找到RF使用多少个基学习器的时候，性能最好。如下图所示， RF的参数由以下决定：

```json
params = {'max_features':'auto', 'max_depth': 6, 'min_samples_split': 2, \
            'oob_score':True}
```

![rfNum](../Image/rfNum.png)

差不多40个基学习器就已经能够获得较低的错误率。增加额外的基学习器在训练数据集上面已经没有太大的意义。

此处打算在border line数据基础上，使用RF引入的属性扰动以及集成学习的机制，看看整体泛化性能是否有所提升。使用50个基学习器构成的RF在border line的数据集上面，获得了0.994624915099的precision，0.994357095192的recall，1.00562076882的$F_2$，混淆矩阵如下图所示：

![RFOrderLineConfuse](../Image/RFOrderLineConfuse.png)

可以看到在precision, recall上面都有较为明显的提升。在原始数据上，获得0.246153846154 precision，0.87074829932的recall，1.73125的$F_2$。混淆矩阵如下图：

![OriginalRFOrderLineConfuse](../Image/OriginalRFOrderLineConfuse.png)







